# ğŸ§  LLM-Powered Personal Research Assistant

This app is a Streamlit-based research assistant that allows users to:

- Upload PDFs or input URLs
- Generate executive summaries
- Ask custom questions about the content
- Get suggested follow-up readings

Powered by Retrieval-Augmented Generation (RAG), vector embeddings, and OpenAI GPT or Claude.

## ğŸš€ Features

- PDF and URL document ingestion
- Text chunking and vector embedding (FAISS or ChromaDB)
- Semantic search for Q&A
- Executive summaries and follow-up suggestions

## ğŸ“¦ Installation

```bash
git clone https://github.com/joeldhamilton/LLM-research-assistant
cd LLM-research-assistant
pip install -r requirements.txt

### ğŸ” Environment Setup

Create a `.env` file in the project root with your OpenAI key:

```env
OPENAI_API_KEY=your_openai_key_here
